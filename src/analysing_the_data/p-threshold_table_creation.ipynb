{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bit891e6b1a097d48fc85f9a7aa3b434b20",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import *\n",
    "import sqlalchemy as sa\n",
    "import pandas as pd\n",
    "\n",
    "database_management_sys = sa.create_engine(\"sqlite:///../database_code/data/se/main.db\")\n",
    "connect_dbms_to_db = database_management_sys.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_tournament_set = \"\"\"\n",
    "    SELECT * FROM folk_theorem_experiment\n",
    "    WHERE tournament_player_set = '20'\n",
    "    AND noise = '0.0'\n",
    "    AND player_strategy_name = 'Defector'\n",
    "\"\"\"\n",
    "trial_data = pd.read_sql(trial_tournament_set, connect_dbms_to_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places_of_jump_up = trial_data.index[trial_data[\"least_prob_of_defection\"] > 0]\n",
    "jump_up_ending_probs = []\n",
    "for index in places_of_jump_up:\n",
    "    if trial_data.iloc[index - 1][\"least_prob_of_defection\"] == 0:\n",
    "        jump_up_ending_probs.append(trial_data.iloc[index][\"prob_of_game_ending\"])\n",
    "jump_up_ending_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jump_up_ending_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_threshold = max_threshold = median_threshold = mean_threshold = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(None, None, None, None)"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_threshold, max_threshold, mean_threshold, median_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_set_collection = \"\"\"\n",
    "    SELECT * FROM folk_theorem_experiment\n",
    "    WHERE tournament_player_set = ?\n",
    "    AND noise = ?\n",
    "    AND player_strategy_name = 'Defector'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['experiment_number',\n 'number_of_players',\n 'tournament_player_set',\n 'player_strategy_name',\n 'is_long_run_time',\n 'is_stochastic',\n 'memory_depth_of_strategy',\n 'prob_of_game_ending',\n 'payoff_matrix',\n 'num_of_repetitions',\n 'num_of_equilibria',\n 'nash_equilibria',\n 'least_prob_of_defection',\n 'greatest_prob_of_defection',\n 'noise',\n 'warning_message']"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_headings = pd.read_sql(\n",
    "    \"folk_theorem_experiment\", connect_dbms_to_db\n",
    ").columns.tolist()#\n",
    "table_headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_relevant_data = connect_dbms_to_db.execute(player_set_collection, (0, 0.0))\n",
    "each_set_data = pd.DataFrame(\n",
    "        collect_relevant_data.fetchall(), columns=table_headings\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each_set_data[\"number_of_players\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_p_thresh(tournament_set):\n",
    "    \"\"\"\n",
    "    A function to find the minimum p-threshold from the database, where:\n",
    "    \n",
    "        \"tournament_set\" is a pandas dataframe containing all the information from the database for one particular set of strategies at one particular noise level.\n",
    "    \"\"\"\n",
    "    defection_prob_at_smallest_prob_game_ending = tournament_set[\"least_prob_of_defection\"][0]\n",
    "    any_equal_prob = tournament_set[tournament_set[\"least_prob_of_defection\"] == defection_prob_at_smallest_prob_game_ending]\n",
    "    if len(tournament_set[\"least_prob_of_defection\"]) == len(any_equal_prob):\n",
    "        if defection_prob_at_smallest_prob_game_ending == 0:\n",
    "        # that is, if the least probability of defection is constant at 0 for all game ending probabilities.    \n",
    "            min_p_thresh = None\n",
    "        else:\n",
    "        # the least probability of defection is equal to some non-zero constant for all game ending probabilities.\n",
    "            min_p_thresh = min(tournament_set[\"prob_of_game_ending\"])\n",
    "    else:\n",
    "        prob_of_defection_is_non_zero = tournament_set[tournament_set[\"least_prob_of_defection\"] != 0]\n",
    "        min_p_thresh = min(prob_of_defection_is_non_zero[\"prob_of_game_ending\"])\n",
    "    return(min_p_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_p_thresh(tournament_set):\n",
    "    \"\"\"\n",
    "    A function to find the maximum p-threshold from the database, where:\n",
    "        \"tournament_set\" is a pandas dataframe containing all the information from the database for one particular set of strategies at one particular noise level.\n",
    "    \"\"\"\n",
    "    defection_prob_at_smallest_prob_game_ending = tournament_set[\"least_prob_of_defection\"][0]\n",
    "    any_equal_prob = tournament_set[tournament_set[\"least_prob_of_defection\"] == defection_prob_at_smallest_prob_game_ending]\n",
    "    if len(tournament_set[\"least_prob_of_defection\"]) == len(any_equal_prob):\n",
    "        if defection_prob_at_smallest_prob_game_ending == 0:\n",
    "        # that is, if the least probability of defection is constant at 0 for all game ending probabilities.    \n",
    "            max_p_thresh = None\n",
    "        else:\n",
    "        # the least probability of defection is equal to some non-zero constant for all game ending probabilities.\n",
    "            max_p_thresh = max(tournament_set[\"prob_of_game_ending\"])\n",
    "    else:\n",
    "        prob_of_defection_is_zero = tournament_set[tournament_set[\"least_prob_of_defection\"] == 0]\n",
    "        prob_of_defection_is_non_zero = tournament_set[tournament_set[\"least_prob_of_defection\"] != 0]\n",
    "        max_zero_defection_game_ending = max(prob_of_defection_is_zero[\"prob_of_game_ending\"])\n",
    "        if len(prob_of_defection_is_non_zero[prob_of_defection_is_non_zero[\"prob_of_game_ending\"] > max_zero_defection_game_ending][\"prob_of_game_ending\"]) == 0:\n",
    "            max_p_thresh = max(prob_of_defection_is_non_zero[\"prob_of_game_ending\"])\n",
    "        else:    \n",
    "            max_p_thresh = min(prob_of_defection_is_non_zero[prob_of_defection_is_non_zero[\"prob_of_game_ending\"] > max_zero_defection_game_ending][\"prob_of_game_ending\"])\n",
    "    return(max_p_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean_p_thresh(tournament_set, min_p_thresh, max_p_thresh):\n",
    "    \"\"\"\n",
    "    A function to find the mean p-threshold from the database, where:\n",
    "        \"tournament_set\" is a pandas dataframe containing all the information from the database for one particular set of strategies at one particular noise level;\n",
    "        \"min_p_thresh\" is a numeric variable between 0 and 1 indicating the minimum p-threshold; and\n",
    "        \"max_p_thresh\" is a numeric variable between 0 and 1 indicating the maximum p-threshold.\n",
    "    \"\"\"\n",
    "    if min_p_thresh == max_p_thresh:\n",
    "        mean_p_thresh = min_p_thresh\n",
    "    else:\n",
    "        prob_of_defection_is_non_zero = tournament_set[tournament_set[\"least_prob_of_defection\"] != 0]\n",
    "        non_zero_defection_prob_between_min_max = prob_of_defection_is_non_zero[(prob_of_defection_is_non_zero[\"prob_of_game_ending\"] >= min_p_thresh) & (prob_of_defection_is_non_zero[\"prob_of_game_ending\"] <= max_p_thresh)]\n",
    "        mean_p_thresh = non_zero_defection_prob_between_min_max[\"prob_of_game_ending\"].mean()\n",
    "    return(mean_p_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_median_p_thresh(tournament_set, min_p_thresh, max_p_thresh):\n",
    "    \"\"\"\n",
    "    A function to find the median p_threshold from the database, where:\n",
    "        \"tournament_set\" is a pandas dataframe containing all the information from the database for one particular set of strategies at one particular noise level;\n",
    "        \"min_p_thresh\" is a numeric variable between 0 and 1 indicating the minimum p-threshold; and\n",
    "        \"max_p_thresh\" is a numeric variable between 0 and 1 indicating the maximum p-threshold.\n",
    "    \"\"\"\n",
    "    if min_p_thresh == max_p_thresh:\n",
    "        median_p_thresh = min_p_thresh\n",
    "    else:\n",
    "        prob_of_defection_is_non_zero = tournament_set[tournament_set[\"least_prob_of_defection\"] != 0]\n",
    "        non_zero_defection_prob_between_min_max = prob_of_defection_is_non_zero[(prob_of_defection_is_non_zero[\"prob_of_game_ending\"] >= min_p_thresh) & (prob_of_defection_is_non_zero[\"prob_of_game_ending\"] <= max_p_thresh)]\n",
    "        median_p_thresh = non_zero_defection_prob_between_min_max[\"prob_of_game_ending\"].median()\n",
    "    return(median_p_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_p_thresh = find_min_p_thresh(tournament_set=trial_data)\n",
    "max_p_thresh = find_max_p_thresh(tournament_set=trial_data)\n",
    "mean_p_thresh = find_mean_p_thresh(tournament_set=trial_data, min_p_thresh=min_p_thresh, max_p_thresh=max_p_thresh)\n",
    "median_p_thresh = find_median_p_thresh(tournament_set=trial_data, min_p_thresh=min_p_thresh, max_p_thresh=max_p_thresh)\n",
    "\n",
    "min_p_thresh, max_p_thresh, mean_p_thresh, median_p_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}