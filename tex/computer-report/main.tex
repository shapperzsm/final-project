This short report summarises the computer work involved in the study. A key aim
of this project was the development and execution of a large experiment
regarding the Iterated Prisoner's Dilemma and the Folk Theorem. As a result of
this, much focus was given to ensuring good software development principles~\cite{Jimenez2017,Sandve2013,Wilson2014} were
followed and hence only a brief overview will be provided here. The interested
reader is encouraged to read Chapter~\ref{} of the main report, where full
details are given.

\section{The Overall Program}
Firstly, the pseudo-code of the program written is provided to give a general
idea of the purpose. This can be found in
Algorithm~\ref{alg:restate_of_main_alg}.

\IncMargin{2em}
\begin{algorithm}
    \DontPrintSemicolon
    \SetKwInOut{Input}{input}
    \SetKwInOut{Output}{output}

    \Input{maximum number of opponents, number of strategy sets for each number
    of opponents, noise levels, game ending probabilities, number of repetitions
    of the tournament, the path to the database file, and whether or not support
    enumeration should be used to calculate the Nash equilibria.}
    \Output{a database containing the results as detailed above.}
    \While{True}{
        \For{each number of opponents}{
            \For{each repetition with the same number of strategies}{
                Randomly select a set of opponents and add in the Defector\\
                \For{each noise level}{
                    \For{each game ending probability}{
                        Run the IPD tournament\\
                        Obtain the Nash equilibria and the corresponding
                        probabilities of defection using the algorithm
                        indicated\\
                        \For{each player in the current set}{
                            Write the required information to a record in the
                            database file.\\
                        }
                    }
                } 
            }
            Repeat
        }
    }
    \caption{Folk Theorem Exploration}\label{alg:restate_of_main_alg}
\end{algorithm}
\DecMargin{2em}

The main functions created were implemented in Python. This was due to its
versatility and, especially, due to the two game theoretic libraries, Axelrod~\cite{axelrodproject}
and Nashpy~\cite{Nashpy2019}, which provided key functions already implemented. Aside from these,
other dependencies of the program include: NumPy, Random, Warnings, os and
SQLAlchemy, plus additional libraries for the analysis (in Chapter~\ref{}). This
program was implemented through the creation of eight functions to ensure the
code was easier to read, debug and test for any current, or future, user.
Furthermore, variables and functions were given descriptive names in order to
produce self-documenting code.

Observe, Algorithm~\ref{alg:restate_of_main_alg} states the use of a database to
retain the information collected. This file type was chosen because it supports
out of memory operations and is known to be robust. In particular, the
relational database SQLite was utilised due to the existence of Python libraries
for accessing the file, its structure and its consistency.

\section{Software Development and Remote Computing}
Version control software Git and associated platform GitHub allowed the author
to keep track of how the program was evolving. It also ensured a back-up copy
was always available, should the system fail and meant that past versions of
functions could be easily accessed. Moreover, GitHub acted as an intermediate
step between between the author's laptop and remote server, used for the main
data collection exercise. 

Due to the volume of data which was to be collected, it was decided that the
program would be executed remotely. This allowed the code to run uninterrupted
for several weeks. However, parallel processing was not required, as the
computational time was deemed `quick enough'.
Figure~\ref{fig:restate_remote_comp} provides a visualisation of how the
author's laptop was connected to the School of Mathematics' headless server,
Siren, via a secure shell (SSH) tunnel and terminal multiplexer TMUX. The latter
ensured the code kept running whilst the author was disconnected from Siren.
Finally, in order to access the database for analysis, the file was compressed
and securely transferred from Siren.

\begin{figure}
    \centering
    \input{tex/chapters/ch3/remote_comp_diag_tikz.tex}
    \caption{Representation of how the experiments were run remotely. Note, `tmux sessions' correspond to emulators of terminals.}\label{fig:restate_remote_comp}
\end{figure}

\section{Further Details}
In conclusion, there were several components to the computing elements of this
study. The reader is referred to the GitHub repository of this project <URL>,
where all the relevant code can be accessed. Also, the data collected during the
study is archived at <URL> for future reference.