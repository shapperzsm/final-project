\chapter{Summary}

This project consists of an empirical study into a class of theorems, entitled
`Folk Theorems', which are a key part of the repeated games theory. The aims of
the project include: an in-depth review of academic literature regarding the
topic; the development and execution of a large experiment based on the
`original' folk theorem of Friedman~\cite{Friedman1971} with the Iterated
Prisoner's Dilemma; and an analysis of the effects of different tournament
characteristics on the \(p\)-threshold appearing in the folk theorems. These
ideas are extended from a third year assignment in Game Theory, completed by the
author.

Firstly, after an introduction to the theory of one-shot and repeated games, a
search of the folk theorem literature is provided in Chapter~\ref{ch:Lit_Review}. This reveals the vast
directions of research in the area for the past fifty years. Many
generalisations and refinements of the folk theorem have been analysed since the
first written papers in the 1970s. The games for which the notion has been
expanded to range from complete information games to games with imperfect
private monitoring. However, in certain cases, the strategies used in the proof
of these are unstable. Also, in situations where an individual deviator cannot
be identified, a much smaller set of payoffs can be achieved, yielding the
so-called `Anti-Folk Theorems'. More recently, focus has been on the application
of the folk theorem to computing and quantum transportation, for example.
Finally, it is concluded that, to the best of the author's knowledge, this is
the fist study to execute an experiment on the folk theorem of this size.

Following this, a detailed description of how the experiment was set-up and
executed is provided in Chapter~\ref{ch:Methods}, with justifications to the specific methods and software
chosen. After considering the benefits and drawbacks of varying file formats for
storing data, it is stated that a relational database, in particular SQLite,
would be the most appropriate. This is due to: the existence of libraries in
Python enabling the easier access of the data; the general robustness of
databases; and its ability to perform out of memory operations. Due to the
pre-existing game theoretic libraries, Axelrod and Nashpy, Python was chosen as
the language of implementation and ensuring good software development principles
were followed is highlighted as a priority. The volume of data which was planned
to be collected meant that remote computing was required and is explained in
this chapter. Here, the choice of support enumeration for the calculation of
Nash equilibria and the potential issues which may be faced due to degeneracy is
also discussed.

The main analysis of the data collected is provided in
Chapter~\ref{ch:Analyses}. An initial analysis discussing the characteristics of
the strategies used and the overall summary statistics is detailed, before the
\(p\)-thresholds are explored. The characteristics of tournaments focused on
are: the number of opponents the Defector had and the level of tournament noise
included. However, this is concluded as a non-trivial task due to the
uncertainty regarding the degeneracy of a large proportion of tournament sets.
Also, the inevitability of randomness within the tournaments meant that a lot
more data than what was obtained is required. On the other hand, the graphs that
were yielded are stated as successful in visualising the folk theorem.

Finally, Chapter~\ref{ch:Conclusions_and_Recommendations} details the
conclusions of the research before giving recommendations for further work.
Amongst these were suggestions on how more characteristics of the tournament set
could be studied as well as the potential to predict the \(p\)-threshold from
the characteristics of the tournaments via regression analysis.